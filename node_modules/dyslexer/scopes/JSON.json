{
  "tokenEnding": [],
  "nesting": 0,


  "onLineStart": {
    "tokensExpected": 1
  },

  "rules": {

    '{': function() {
      if(self.lexer.scoper === '{') {
        self.nesting++;
      }
    },

    '[': function() {
      if(self.lexer.scoper === '[') {
        self.nesting++;
      }
    },

    '}': function() {
      if(self.lexer.scoper === '{') {
        if(self.nesting) {
          self.nesting--;
        } else {
          self.lexer.fireToken();
        }
      }
    },

    ']': function() {
      if(self.lexer.scoper === '[') {
        if(self.nesting) {
          self.nesting--;
        } else {
          self.lexer.fireToken();
        }
      }
    }

  },

  "structure": [ ['DATA'] ]
  "onToken": {
    "token": "DATA"
  }

};

// How to translate / fix this
// Functionality does not belong in a lexer
// Lexer should only present the token as is.
// It's actually a bug work around even, token
// is missing the last part, which is wrong..
// which means fireToken is not doing what it is supposed to
// It is however the char is cut off..
// Anywayy.. means the below logic is not necessary.

JSONScope.prototype.onToken = function(token) {

  var inverse = {
    '{': '}',
    '[': ']'
  };

  // Note! it must be defined as real json,
  // so mind those quotes
  var line = [
    token,
    // a bit ugly, but as long as it's constantly ugly
    // it doesn't matter.
    // (scanner char is never added to the token value)
    inverse[this.lexer.scoper]
  ].join('');
  token = JSON.parse(line);

  this.lexer.present('DATA', token);
};

module.exports = JSONScope;
